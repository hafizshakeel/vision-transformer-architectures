# Vision Transformer Architectures

A collection of Vision Transformer (ViT) implementations and variants in PyTorch. This repository aims to provide clean, modular implementations of various vision transformer architectures.

## Currently Implemented Models

### [Vision Transformer (ViT)](Vision%20Transformer/)
- Implementation of the original Vision Transformer model from "An Image is Worth 16x16 Words" paper
- Complete training pipeline with CIFAR-10 dataset support
- Configurable architecture and training parameters

## Getting Started

1. Clone the repository:
```bash
git clone https://github.com/hafizshakeel/vision-transformer-architectures.git
cd vision-transformer-architectures
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Navigate to the specific model implementation:
```bash
cd "Vision Transformer"
```

4. Follow the model-specific README for training and usage instructions.

## License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Contact
Email: hafizshakeel1997@gmail.com